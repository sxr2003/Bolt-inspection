# BoltLooseningDetection v2.2: Multi-Modal Attention Fusion Framework

![PyTorch](https://img.shields.io/badge/PyTorch-2.0%2B-EE4C2C.svg?style=flat-square&logo=pytorch)
![License](https://img.shields.io/badge/license-MIT-blue.svg?style=flat-square)
![Status](https://img.shields.io/badge/status-Active-success.svg?style=flat-square)
![Config](https://img.shields.io/badge/Config-222-brightgreen.svg?style=flat-square)

## ğŸ“– Project Overview

**BoltLooseningDetection v2.2** æ˜¯ä¸€ä¸ªé«˜æ€§èƒ½çš„æ·±åº¦å­¦ä¹ æ¡†æ¶ï¼Œä¸“ä¸ºå·¥ä¸šèºæ “æ¾åŠ¨æ£€æµ‹è®¾è®¡ã€‚å®ƒé‡‡ç”¨å…ˆè¿›çš„ **å¤šæ¨¡æ€ "2-2-2" æ¶æ„**ï¼Œç»“åˆ 1D æŒ¯åŠ¨ä¿¡å·å’Œ 2D æ—¶é¢‘å›¾åƒï¼Œå®ç°äº† 16 ç§ä¸åŒæ¾åŠ¨çŠ¶æ€çš„é²æ£’åˆ†ç±»ã€‚

## ğŸ“‚ Directory Structure

```text
BoltLooseningDetection/
â”œâ”€â”€ config.json           # æ ¸å¿ƒé…ç½® (è®¾ç½®ä¸º "222" æ¨¡å¼)
â”œâ”€â”€ dataset.py            # æ•°æ®åŠ è½½ã€5é€šé“å›¾åƒç”Ÿæˆã€å¢å¼º
â”œâ”€â”€ generalization.py     # æ³›åŒ–æ€§æµ‹è¯•è„šæœ¬
â”œâ”€â”€ model.py              # ResNet101, Hybrid Signal Encoder, Attention Fusion
â”œâ”€â”€ train.py              # ä¸»è®­ç»ƒæµç¨‹
â”œâ”€â”€ checkpoints/          # æ¨¡å‹æƒé‡å­˜å‚¨
â”œâ”€â”€ logs/                 # TensorBoard æ—¥å¿—å’Œæ··æ·†çŸ©é˜µ
â””â”€â”€ data/                 # æ•°æ®é›†ç›®å½• (Case1 - Case16)
```

---

## âš™ï¸ Environmental Requirements

è¦ç¡®ä¿æ‰€æœ‰ä¾èµ–é¡¹éƒ½æ­£ç¡®å®‰è£…ï¼Œè¯·è¿è¡Œä»¥ä¸‹å‘½ä»¤ï¼š

```bash
pip install torch torchvision numpy pandas \\
            scipy librosa opencv-python scikit-learn \\
            matplotlib seaborn tqdm tensorboard
```

> **Note:** `os.environ['TF_ENABLE_ONEDNN_OPTS'] = '0'` å·²åœ¨ `train.py` ä¸­è‡ªåŠ¨è®¾ç½®ä»¥ç¡®ä¿å…¼å®¹æ€§ã€‚

---

## ğŸ”§ Configuration (`config.json`)

é»˜è®¤ `config.json` è®¾ç½®ä¸º **"222"** é«˜æ€§èƒ½æ¨¡å¼ï¼š

```json
"modality": {
    "pseudo_image_mode": 1,   // 5-channel mode
    "image_model": {
        "type": 2,            // 2 = ResNet101
        "in_channels": 5,
        "out_dim": 256,
        "pretrained": true
    },
    "signal_model": {
        "type": 2,            // 2 = Hybrid (CNN+LSTM+Transformer)
        "embed_dim": 256,
        "nhead": 8
    },
    "fusion": {
        "type": 2,            // 2 = Multi-Head Attention Fusion
        "num_heads": 4
    }
}
```

---

## ğŸš€ Usage

### 1. Training

å¯åŠ¨å®Œæ•´çš„è®­ç»ƒæµç¨‹ã€‚è„šæœ¬ä¼šåœ¨é¦–æ¬¡è¿è¡Œæ—¶è‡ªåŠ¨è®¡ç®—ä¿¡å·ç»Ÿè®¡æ•°æ® (mean/std)ã€‚

```bash
python train.py
```

* **Output:** æœ€ä½³æ¨¡å‹ä¿å­˜åˆ° `./checkpoints/best_model_*.pth`ã€‚
* **Logging:** æŒ‡æ ‡ (æŸå¤±/ç²¾åº¦) è®°å½•åˆ° TensorBoardï¼›æ··æ·†çŸ©é˜µä¿å­˜åˆ° `./logs`ã€‚

### 2. Generalization Test

åœ¨ç‰¹å®šçš„æœªè§æ¡ˆä¾‹æˆ–å®Œæ•´æ•°æ®é›†ä¸Šè¯„ä¼°è®­ç»ƒå¥½çš„æ¨¡å‹ï¼Œä»¥è·å–è¯¦ç»†æŒ‡æ ‡ã€‚

```bash
python generalization.py
```

* **Output:** è¯¦ç»†çš„åˆ†ç±»æŠ¥å‘Š (ç²¾ç¡®åº¦ã€å¬å›ç‡ã€F1) å’Œåˆ†æ¡ˆä¾‹ç²¾åº¦ã€‚

---

## ğŸ“Š Visualization

æ‚¨å¯ä»¥ä½¿ç”¨ TensorBoard ç›‘æ§è®­ç»ƒè¿›åº¦å¹¶æŸ¥çœ‹æ··æ·†çŸ©é˜µï¼š

```bash
tensorboard --logdir=./logs
```

é¡¹ç›®è¿˜ä¼šåœ¨æµ‹è¯•åè‡ªåŠ¨åœ¨ `./logs` æ–‡ä»¶å¤¹ä¸­ç”Ÿæˆ **æ··æ·†çŸ©é˜µçƒ­å›¾ (PNG)**ã€‚

---

## ğŸ“ License

æœ¬é¡¹ç›®åœ¨ MIT è®¸å¯è¯ä¸‹å¼€æºã€‚
